name: CI

on:
  push:
    branches:
      - main
  pull_request:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  build-and-test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install build dependencies
        run: sudo apt-get update && sudo apt-get install -y build-essential

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install pyyaml

      - name: Build test binaries
        working-directory: chrono-C-all
        run: |
          make clean
          make tests

      - name: Run regression suite
        id: run_tests
        working-directory: chrono-C-all
        continue-on-error: true
        run: |
          rm -f ../test.log
          set -o pipefail
          if make test > ../test.log 2>&1; then
            echo "Test run completed. Showing tail of test.log:"
            tail -n 120 ../test.log
            exit 0
          else
            echo "Test run failed. Showing tail of test.log:"
              tail -n 400 ../test.log
              exit 1
          fi

      - name: Enforce diagnostics ABI
        if: always()
        working-directory: chrono-C-all
        run: tests/test_constraint_common_abi

      - name: Capture contact Jacobian log
        if: always()
        working-directory: chrono-C-all
        run: |
          mkdir -p ../artifacts/contact
          tests/test_island_parallel_contacts \
            --jacobian-log ../artifacts/contact/contact_jacobian_log.csv

      - name: Tag coupled/island ranges
        if: always()
        run: |
          python3 tools/filter_ci_failures.py test.log --tag-input

      - name: Extract coupled/island failures
        if: always()
        run: |
          python3 tools/filter_ci_failures.py test.log --output test_coupled_island.log

      - name: Lint coupled endurance CSV headers
        if: always()
        run: |
          python3 tools/filter_coupled_endurance_log.py \
            data/coupled_constraint_endurance.csv \
            --lint-only \
            --require condition_number_spectral,condition_gap,min_eigenvalue,max_eigenvalue,active_equations,drop_events_total

      - name: Validate endurance CSV filter
        if: always()
        run: |
          tmpfile=$(mktemp)
          cp data/coupled_constraint_endurance.csv "$tmpfile"
          python3 tools/filter_coupled_endurance_log.py "$tmpfile"
          python3 tools/plot_coupled_constraint_endurance.py "$tmpfile" --skip-plot --summary-json /tmp/filtered_summary.json --no-show
          rm -f "$tmpfile"

      - name: Validate sample latest.summary schema
        if: always()
        run: |
          mkdir -p artifacts/ci
          python3 tools/validate_latest_summary_schema.py \
            --summary-json /tmp/filtered_summary.json \
            --output-markdown artifacts/ci/sample_latest_summary.md \
            --output-json artifacts/ci/sample_latest_summary.json \
            --fail-on-error

      - name: Generate condition gap report
        if: always()
        run: |
          mkdir -p artifacts/ci
          python3 tools/report_coupled_condition_gap.py \
            --input data/coupled_benchmark_metrics.csv \
            --output artifacts/ci/condition_gap_report.md

      - name: Upload test log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: chrono-tests
          path: |
            test.log
            test_coupled_island.log
            artifacts/ci/condition_gap_report.md
            artifacts/ci/sample_latest_summary.md
            artifacts/ci/sample_latest_summary.json
            artifacts/contact

      - name: Fail if tests failed
        if: steps.run_tests.outcome == 'failure'
        run: exit 1

      - name: Run coupled benchmark
        run: |
          python3 tools/run_coupled_benchmark.py \
            --config config/coupled_benchmark_thresholds.yaml \
            --output data/coupled_benchmark_metrics.csv \
            --csv-validation warn

      - name: Upload coupled benchmark CSV
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coupled-benchmark
          path: data/coupled_benchmark_metrics.csv

  descriptor-e2e:
    needs: build-and-test
    runs-on: ubuntu-latest
    strategy:
      matrix:
        mode: [actions]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install build dependencies
        run: sudo apt-get update && sudo apt-get install -y build-essential

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install pyyaml

      - name: Build descriptor test
        working-directory: chrono-C-all
        run: |
          make clean
          make tests/test_coupled_constraint

      - name: Run descriptor mode ${{ matrix.mode }}
        working-directory: chrono-C-all
        run: |
          mkdir -p ../artifacts/descriptor
          tests/test_coupled_constraint \
            --use-kkt-descriptor \
            --descriptor-mode ${{ matrix.mode }} \
            --descriptor-log ../artifacts/descriptor/kkt_descriptor_${{ matrix.mode }}_${{ github.run_id }}.csv \
            --pivot-artifact-dir ../artifacts/descriptor/run-${{ github.run_id }}

      - name: Upload descriptor artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coupled-descriptor-${{ matrix.mode }}
          path: artifacts/descriptor
