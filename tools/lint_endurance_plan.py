#!/usr/bin/env python3
"""
Lint helper for endurance archive plan CSV files.

The archive pipeline can emit a ``plan.csv`` describing archive/delete actions.
This script scans the plan for duplicate hashes and self-cancelling operations
so that retention policies can be reviewed quickly.
"""

from __future__ import annotations

import argparse
import csv
from collections import defaultdict
from pathlib import Path
from typing import Dict, Iterable, List, Sequence


def parse_args(argv: Sequence[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Identify redundant entries in endurance archive plan CSV files."
    )
    parser.add_argument(
        "plans",
        nargs="+",
        help="One or more plan.csv files generated by archive_coupled_constraint_endurance.py.",
    )
    parser.add_argument(
        "--fail-on-duplicates",
        action="store_true",
        help="Exit with status 1 when duplicate hashes are detected.",
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="Suppress detailed output; only the exit status reflects findings.",
    )
    return parser.parse_args(argv)


def read_plan(path: Path) -> List[Dict[str, str]]:
    try:
        with path.open("r", newline="", encoding="utf-8") as handle:
            reader = csv.DictReader(handle)
            return [dict(row) for row in reader]
    except FileNotFoundError as exc:
        raise RuntimeError(f"plan CSV not found: {path}") from exc


def group_by_hash(records: Iterable[Dict[str, str]]) -> Dict[str, List[Dict[str, str]]]:
    buckets: Dict[str, List[Dict[str, str]]] = defaultdict(list)
    for row in records:
        hash_value = (row.get("hash") or "").strip()
        if hash_value:
            buckets[hash_value].append(row)
    return buckets


def find_self_cancelling(records: Iterable[Dict[str, str]]) -> List[tuple[str, List[Dict[str, str]]]]:
    by_target: Dict[str, List[Dict[str, str]]] = defaultdict(list)
    for row in records:
        target = (row.get("target") or "").strip()
        if target:
            by_target[target].append(row)

    offenders: List[tuple[str, List[Dict[str, str]]]] = []
    for target, rows in by_target.items():
        has_archive = any(row.get("action") == "archive" for row in rows)
        has_delete = any(row.get("action") == "delete" for row in rows)
        if has_archive and has_delete:
            offenders.append((target, rows))
    return offenders


def describe_row(row: Dict[str, str]) -> str:
    action = row.get("action", "")
    reason = row.get("reason", "")
    detail = row.get("detail", "")
    return f"{action} (reason={reason or 'n/a'}, detail={detail or 'n/a'})"


def lint_plan(path: Path, quiet: bool = False) -> bool:
    rows = read_plan(path)
    duplicate_hashes = {
        hash_value: entries
        for hash_value, entries in group_by_hash(rows).items()
        if len(entries) > 1
    }
    self_cancelling = find_self_cancelling(rows)

    if quiet:
        return bool(duplicate_hashes or self_cancelling)

    print(f"=== {path} ===")
    if not rows:
        print("No entries found.")
    if duplicate_hashes:
        print(f"Duplicate hashes ({len(duplicate_hashes)} groups):")
        for hash_value, entries in duplicate_hashes.items():
            actions = ", ".join(describe_row(entry) for entry in entries)
            print(f" - {hash_value[:12]}â€¦ -> {actions}")
    else:
        print("No duplicate hashes detected.")

    if self_cancelling:
        print(f"Self-cancelling targets ({len(self_cancelling)}):")
        for target, entries in self_cancelling:
            actions = ", ".join(describe_row(entry) for entry in entries)
            print(f" - {target}: {actions}")
    else:
        print("No archive/delete overlaps detected.")

    return bool(duplicate_hashes or self_cancelling)


def main(argv: Sequence[str] | None = None) -> int:
    args = parse_args(argv)
    duplicates_found = False

    for plan_path in args.plans:
        path = Path(plan_path).expanduser()
        has_duplicates = lint_plan(path, quiet=args.quiet)
        duplicates_found = duplicates_found or has_duplicates

    if args.fail_on_duplicates and duplicates_found:
        return 1
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
